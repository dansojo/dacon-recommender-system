{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kKyQ67JU92kHxLWEctIDkkMroElt2Xo7",
      "authorship_tag": "ABX9TyOlSdBG17An4o8Plh1TL4g4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh-0620/dacon-recommender-system/blob/main/recommendations_TfidfVectorizer(all)_content_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "\n",
        "# CSV 파일 로드\n",
        "log_df = pd.read_csv(\"/content/drive/MyDrive/웹 기사 추천시스템/view_log.csv\")  # 유저 로그 데이터\n",
        "article__df = pd.read_csv(\"/content/drive/MyDrive/웹 기사 추천시스템/article_info.csv\")  # 기사 데이터\n",
        "article_nouns_df = pd.read_csv(\"/content/drive/MyDrive/웹 기사 추천시스템/article_nouns.csv\")  # 기사 데이터"
      ],
      "metadata": {
        "id": "pWvLTs74aG2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_nouns_df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vje9BOGRBm5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_nouns_df = article_nouns_df.drop(['userCountry', 'userRegion', 'userID'], axis=1)"
      ],
      "metadata": {
        "id": "lF5psW-mUY9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(log_df, article_nouns_df, on='articleID')"
      ],
      "metadata": {
        "id": "fydMBRahinru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기사 데이터 중 로그 데이터에 없는 기사 제거\n",
        "article_nouns_df  = article_nouns_df[article_nouns_df['articleID'].isin(merged_df['articleID'].unique())]"
      ],
      "metadata": {
        "id": "lOgq9-oNixkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 인코더 생성 및 학습\n",
        "article_label_encoder = LabelEncoder()\n",
        "merged_df['articleID'] = article_label_encoder.fit_transform(merged_df['articleID'])\n",
        "article_nouns_df['articleID'] = article_label_encoder.transform(article_nouns_df['articleID'])"
      ],
      "metadata": {
        "id": "8s8DzvhiodoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저 아이디 라벨 인코딩 적용\n",
        "user_label_encoder = LabelEncoder()\n",
        "merged_df['userID'] = user_label_encoder.fit_transform(merged_df['userID'])"
      ],
      "metadata": {
        "id": "6N4f0JpdojzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_df 원핫 인코딩\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "# 범주형 변수 선택 (지역, 나라)\n",
        "log_df_categories = log_df[['userRegion', 'userCountry']]\n",
        "\n",
        "# One-Hot Encoding 수행\n",
        "log_df_encoded_categories = encoder.fit_transform(log_df_categories).toarray()"
      ],
      "metadata": {
        "id": "0RUncDyyladF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# article_nouns_df 원핫 인코딩\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "# 범주형 변수 선택 (언어, 형식)\n",
        "article_nouns_df_categories = article_nouns_df[['Format', 'Language']]\n",
        "\n",
        "# One-Hot Encoding 수행\n",
        "article_nouns_df_encoded_categories = encoder.fit_transform(article_nouns_df_categories).toarray()"
      ],
      "metadata": {
        "id": "b_Jims6CUZPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기사 데이터 전처리: 제목 + 본문\n",
        "tfidf = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    max_features=10000,\n",
        "    ngram_range=(1, 2),\n",
        "    max_df=0.8,\n",
        "    min_df=3,\n",
        "    sublinear_tf=True,\n",
        "    smooth_idf=True\n",
        ")\n",
        "tfidf_matrix = tfidf.fit_transform(article_nouns_df['Title'] + ' ' + article_nouns_df['Content'])"
      ],
      "metadata": {
        "id": "C8dmLWfkUZIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF 행렬, article_nouns_df 원핫 인코딩 / log_df 원핫 인코딩 / => 피처 벡터 결합\n",
        "combined_features = np.hstack((tfidf_matrix.toarray(), article_nouns_df_encoded_categories))\n"
      ],
      "metadata": {
        "id": "P2KmTHW85bnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저별 기사 읽기 패턴 추출\n",
        "user_read_articles = defaultdict(list)\n",
        "for _, row in merged_df.iterrows():\n",
        "    user_read_articles[row['userID']].append(row['articleID'])"
      ],
      "metadata": {
        "id": "3loQC9ua6HPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유저 기반 협업 필터링 모델\n",
        "def recommend_articles(userID, top_n=5):\n",
        "    if userID not in user_read_articles or not user_read_articles[userID]:\n",
        "\n",
        "        return article_nouns_df.sample(n=top_n)[['Title', 'Content']]\n",
        "\n",
        "\n",
        "    read_articles = user_read_articles[userID]\n",
        "    read_articles_features = combined_features[read_articles]\n",
        "\n",
        "    if read_articles_features.shape[0] == 0:\n",
        "        return article_nouns_df.sample(n=top_n)[['Title', 'Content']]\n",
        "\n",
        "    # 사용자가 읽은 기사들의 피처 벡터 평균 계산\n",
        "    avg_features = np.mean(read_articles_features, axis=0).reshape(1, -1)\n",
        "\n",
        "    # 사용자가 읽은 기사들의 피처 벡터 평균과 모든 기사들의 피처 벡터 간의 코사인 유사도 계산 (콘텐츠 기반 필터링)\n",
        "    content_similarities = cosine_similarity(avg_features, combined_features).flatten()\n",
        "\n",
        "    # 모든 사용자의 읽은 기사 정보를 고려하여 협업 필터링 기반 유사도 계산\n",
        "    collaborative_similarities = np.zeros(len(combined_features))\n",
        "    for other_user, other_user_read_articles in user_read_articles.items():\n",
        "        if other_user == userID:\n",
        "            continue\n",
        "        # 다른 사용자가 읽은 기사들과 현재 사용자의 읽은 기사의 피처 벡터 간의 유사도 계산\n",
        "        other_user_features = combined_features[other_user_read_articles]\n",
        "        other_user_avg_features = np.mean(other_user_features, axis=0).reshape(1, -1)\n",
        "        collaborative_similarities += cosine_similarity(other_user_avg_features, combined_features).flatten()\n",
        "\n",
        "    # 콘텐츠 기반 필터링과 협업 필터링의 유사도 합산 (가중치 적용 가능)\n",
        "    hybrid_similarities = content_similarities + collaborative_similarities\n",
        "\n",
        "    # # 사용자가 읽은 기사들의 피처 벡터 평균과 모든 기사들의 피처 벡터 간의 코사인 유사도 계산\n",
        "    # similarities = cosine_similarity(avg_features, combined_features)\n",
        "\n",
        "    # 유사도가 높은 상위 top_n 개의 기사 인덱스 추출\n",
        "    similar_articles_indices = hybrid_similarities.argsort()[-top_n:][::-1]\n",
        "\n",
        "    # 추천 기사 반환 (유저가 읽은 기사 포함)\n",
        "    recommendations = article_nouns_df.iloc[similar_articles_indices]\n",
        "    return recommendations[['Title', 'Content']]"
      ],
      "metadata": {
        "id": "6DoBpMp9hJ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_recommendations = []\n",
        "\n",
        "for encoded_user_id in merged_df['userID'].unique():\n",
        "    # 추천 기사 인덱스 가져오기\n",
        "    recommended_articles = recommend_articles(encoded_user_id)\n",
        "\n",
        "    # 원래 유저 아이디로 역변환\n",
        "    original_user_id = user_label_encoder.inverse_transform([encoded_user_id])[0]\n",
        "\n",
        "    for idx in recommended_articles.index:\n",
        "        # 원래 기사 아이디로 역변환\n",
        "        original_article_id = article_label_encoder.inverse_transform([article_nouns_df.loc[idx, 'articleID']])[0]\n",
        "\n",
        "        # 추천 결과를 리스트에 저장\n",
        "        user_recommendations.append({\n",
        "            'userID': original_user_id,\n",
        "            'articleID': original_article_id\n",
        "        })"
      ],
      "metadata": {
        "id": "PTI_MVJU0Bef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_recommendations)"
      ],
      "metadata": {
        "id": "lIfqs18V4RYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations_df = pd.DataFrame(user_recommendations)\n",
        "recommendations_df.to_csv('user_recommendations_(all)_content_tune_ collabo.csv', index=False)"
      ],
      "metadata": {
        "id": "tbLdf3V_4YmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}